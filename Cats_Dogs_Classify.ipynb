{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats_Dogs_Classify.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtyn/AI-Practice-Tensorflow-Notes/blob/master/Cats_Dogs_Classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNz-4uxv-pgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "73dbb350-db81-4aad-ab01-bff5e2c95506"
      },
      "source": [
        "!python ./cats_dogs_classify.py\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0626 09:52:24.554058 140482110207872 deprecation_wrapper.py:119] From ./cats_dogs_classify.py:34: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0626 09:52:24.554463 140482110207872 deprecation_wrapper.py:119] From ./cats_dogs_classify.py:38: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"./cats_dogs_classify.py\", line 158, in <module>\n",
            "    dataset_test = get_dataset([test_file], batch_size=32, shuffle_num=0)\n",
            "  File \"./cats_dogs_classify.py\", line 64, in get_dataset\n",
            "    dataset = dataset.map(_preprocess_image)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1772, in map\n",
            "    MapDataset(self, map_func, preserve_cardinality=False))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3197, in __init__\n",
            "    **flat_structure(self))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2470, in map_dataset\n",
            "    preserve_cardinality=preserve_cardinality, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 366, in _apply_op_helper\n",
            "    g = ops._get_graph_from_inputs(_Flatten(keywords.values()))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6135, in _get_graph_from_inputs\n",
            "    _assert_same_graph(original_graph_element, graph_element)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6071, in _assert_same_graph\n",
            "    (item, original_item))\n",
            "ValueError: Tensor(\"Const:0\", shape=(3,), dtype=float32) must be from the same graph as Tensor(\"MapDataset_2:0\", shape=(), dtype=variant).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r9YHJDrMYew",
        "colab_type": "code",
        "outputId": "8f66343a-a699-4738-fae8-a40ac87e0401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 运行此单元格即可装载您的 Google 云端硬盘。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK3J63gHMV-D",
        "colab_type": "text"
      },
      "source": [
        "# 数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1ygh3CFM4yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.python.keras.layers import Flatten, Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.python.keras.models import Model, load_model\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.python.keras.initializers import TruncatedNormal\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "image_size = 224\n",
        "is_gpu = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrS50_yrLB5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def parse_exmp(serial_exmp):\n",
        "    # filename_queue = tf.train.string_input_producer(file_list)  # 建立一个队列，其中的参数为tfrecords文件的路径\n",
        "    # reader = tf.TFRecordReader()  # 实例化读操作，建立读取器\n",
        "    # _, serialized_example = reader.read(filename_queue)  # 返回文件名和文件\n",
        "\n",
        "    keys_to_features = {\n",
        "        'image': tf.FixedLenFeature([], tf.string),\n",
        "        'label': tf.FixedLenFeature([], tf.int64)\n",
        "    }\n",
        "\n",
        "    feats = tf.parse_single_example(serial_exmp, keys_to_features)\n",
        "\n",
        "    # image = tf.decode_raw(feats['image'], tf.uint8)\n",
        "    # label = feats['label']\n",
        "\n",
        "    image = tf.decode_raw(feats['image'], tf.uint8)\n",
        "    \n",
        "    label = tf.cast(feats['label'], tf.int64)\n",
        "    \n",
        "    return image, label\n",
        "\n",
        "\n",
        "def _preprocess_image(image, label):\n",
        "    \n",
        "    _image = preprocess_input(image)\n",
        "    \n",
        "    return _image, label\n",
        "    \n",
        "\n",
        "\n",
        "def get_dataset(file_list, shuffle_num=0, batch_size=32):\n",
        "    \n",
        "    \n",
        "    dataset = tf.data.TFRecordDataset(file_list)\n",
        "\n",
        "    # Maps the parser on every filepath in the array. You can set the number of parallel loaders here\n",
        "    dataset = dataset.map(parse_exmp)\n",
        "    \n",
        "    # 使用lambda函数处理(归一化)\n",
        "#     dataset = dataset.map(lambda image, label : (preprocess_input(image), label))\n",
        "#     dataset = dataset.map(lambda image, label: preprocess_image(image, label))\n",
        "    \n",
        "#     dataset = dataset.map(_preprocess_image)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # This dataset will go on forever\n",
        "\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "    # Set the number of datapoints you want to load and shuffle\n",
        "    if shuffle_num > 0:\n",
        "        dataset = dataset.shuffle(shuffle_num)\n",
        "\n",
        "    # Set the batchsize\n",
        "\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Create an iterator\n",
        "\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "    # Create your tf representation of the iterator\n",
        "    \n",
        "    image, label = iterator.get_next()\n",
        "    \n",
        "    \n",
        "    # Bring your picture back in shape\n",
        "    \n",
        "    image = tf.reshape(image, [-1, image_size, image_size, 3])\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = preprocess_input(image)\n",
        "    \n",
        "    # Create a one hot array for your labels\n",
        "    \n",
        "    label = tf.one_hot(label, 2)\n",
        "    \n",
        "    return image, label\n",
        "\n",
        "\n",
        "\n",
        "# 数据迭代\n",
        "def generator(dataset):\n",
        "    \n",
        "    next_op = dataset.make_one_shot_iterator().get_next()\n",
        "    print('----->>')\n",
        "    with tf.Session() as sess:\n",
        "        print('----->>')\n",
        "        init_op = tf.global_variables_initializer()\n",
        "        sess.run(init_op)\n",
        "#         coord = tf.train.Coordinator()\n",
        "#         threads = tf.train.start_queue_runners(coord=coord)\n",
        "        print('----->>')\n",
        "        \n",
        "        x, y = sess.run(next_op)\n",
        "        return x, y\n",
        "    \n",
        "#         while True:\n",
        "            \n",
        "#             x, y = sess.run(next_op)\n",
        "#             #                 x = np.array(x).reshape((-1, size))\n",
        "#             #                 y = np.array(y).reshape((-1, CLASSIFY_NUM))\n",
        "#             print('----')\n",
        "#             x = np.array(x).reshape((-1, image_size, image_size, 3))\n",
        "# #             x = preprocess_input(x)\n",
        "#             y = np.array(y).reshape((-1, 2))\n",
        "            \n",
        "#             yield (x, y)\n",
        "# #             coord.request_stop()\n",
        "# #             coord.join(threads)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyF0s1YFM-y4",
        "colab_type": "code",
        "outputId": "231c433f-8106-4793-de12-bb0241966a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "\n",
        "\n",
        "# 训练集\n",
        "train_file = '/content/drive/My Drive/dataset/cats_dogs/cats_dogs_train_224_224.tfrecords'\n",
        "\n",
        "x_train, y_train = get_dataset([train_file], batch_size=210, shuffle_num=21000)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 测试集\n",
        "test_file = '/content/drive/My Drive/dataset/cats_dogs/cats_dogs_test_224_224.tfrecords'\n",
        "\n",
        "x_test, y_test = get_dataset([test_file], batch_size=32, shuffle_num=0)\n",
        "\n",
        "# x_test, y_test = dataset_test.make_one_shot_iterator().get_next()\n",
        "\n",
        "# x_test_all = []\n",
        "# y_test_all = []\n",
        "\n",
        "\n",
        "# with tf.Session() as sess:\n",
        "#     init_op = tf.global_variables_initializer()\n",
        "#     sess.run(init_op)\n",
        "#     for i in range(4004//32):\n",
        "#         image, label = sess.run((x_test, y_test))\n",
        "#         x_test_all.append(image)\n",
        "#         y_test_all.append(label)\n",
        "#         # save_image('logs/%d.png' % i, image[0])\n",
        "\n",
        "# x_test_all = np.array(x_test_all).reshape((-1, image_size, image_size, 3))\n",
        "\n",
        "# x_test_all = preprocess_input(x_test_all)\n",
        "\n",
        "# y_test_all = np.array(y_test_all).reshape((-1, 2))\n",
        "\n",
        "# print(x_test_all.shape)\n",
        "# print(y_test_all.shape)\n",
        "\n",
        "# print(x_test_all[0])\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0626 10:15:03.923094 139955496589184 deprecation.py:323] From <ipython-input-6-db69a3a48ddb>:62: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbmktLA9LpJZ",
        "colab_type": "text"
      },
      "source": [
        "# 模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpEoEX4QNzVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainsport_resnet50:\n",
        "    \n",
        "    @staticmethod\n",
        "    def build():\n",
        "        \n",
        "        # base_model = ResNet50(weights='imagenet', include_top=False, pooling=None,\n",
        "        #                       input_shape=(img_weight, img_height, color), classes=nb_classes)\n",
        "        base_model_weights_path = '/content/drive/My Drive/model/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, \n",
        "                              input_shape=(image_size, image_size, 3), \n",
        "                              \n",
        "                              classes=2)\n",
        "\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        x = base_model.output\n",
        "\n",
        "        x = Flatten()(x)\n",
        "\n",
        "#         x = GlobalAveragePooling2D()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        \n",
        "        x = Dense(256, activation='relu',\n",
        "                 kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.01))(x)\n",
        "        \n",
        "        x = Dropout(0.5)(x)\n",
        "        \n",
        "        predictions = Dense(2, activation='softmax', \n",
        "                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.01))(x)\n",
        "\n",
        "        inputs = base_model.input\n",
        "        outputs = predictions\n",
        "\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        \n",
        "#         model.summary()\n",
        "        \n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZVeXGzoLrPB",
        "colab_type": "text"
      },
      "source": [
        "# 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6rIug0oPp7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "outputId": "a6b40a7c-0e58-48b0-b6d1-474803eff4a2"
      },
      "source": [
        "\n",
        "H = None\n",
        "\n",
        "if is_gpu:\n",
        "    \n",
        "    model = Trainsport_resnet50.build()\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\",  \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "\t          metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    mc = ModelCheckpoint('cats_dogs_best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "\n",
        "    H = model.fit(x_train, y_train, \n",
        "          epochs=50, \n",
        "          steps_per_epoch=100, \n",
        "          validation_data=(x_test, y_test), \n",
        "          validation_steps=4004//32, \n",
        "          callbacks=[es, mc]\n",
        "         )\n",
        "    \n",
        "   \n",
        "\n",
        "#     H = model.fit(x_train, y_train,\n",
        "#                    epochs=100, \n",
        "#                    steps_per_epoch=100, \n",
        "#                    validation_data=(x_test, y_test),\n",
        "#                    validation_steps=4004//32,\n",
        "#                    validation_freq=5\n",
        "#                   )\n",
        " \n",
        "\n",
        "# model.fit(train_x, train_y, epochs=20, steps_per_epoch=100, validation_data=(test_x, test_y), validation_freq=10)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "W0626 09:52:38.151105 139784028768128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 126s 1s/step - loss: 0.0922 - acc: 0.9634 - val_loss: 0.0426 - val_acc: 0.9855\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 102s 1s/step - loss: 0.0427 - acc: 0.9843 - val_loss: 0.0417 - val_acc: 0.9865\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 100s 1s/step - loss: 0.0220 - acc: 0.9920 - val_loss: 0.0484 - val_acc: 0.9860\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 100s 1s/step - loss: 0.0144 - acc: 0.9949 - val_loss: 0.0503 - val_acc: 0.9872\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 98s 979ms/step - loss: 0.0096 - acc: 0.9966 - val_loss: 0.0548 - val_acc: 0.9858\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 99s 987ms/step - loss: 0.0076 - acc: 0.9972 - val_loss: 0.0563 - val_acc: 0.9868\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 97s 972ms/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0618 - val_acc: 0.9858\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 98s 976ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0592 - val_acc: 0.9872\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 98s 977ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.0652 - val_acc: 0.9872\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 98s 978ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0689 - val_acc: 0.9862\n",
            "Epoch 11/50\n",
            " 55/100 [===============>..............] - ETA: 36s - loss: 0.0030 - acc: 0.9990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4ab50e097135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4004\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m          )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m           \u001b[0;31m# `ins` can be callable in tf.distribute.Strategy + eager case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhzwyzZQLdPP",
        "colab_type": "text"
      },
      "source": [
        "# TPU训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTpsdqLRflHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# tpu训练\n",
        "if not is_gpu:\n",
        "    \n",
        "    \n",
        "    \n",
        "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)\n",
        "\n",
        "    tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "\n",
        "    strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "\n",
        "    with strategy.scope():\n",
        "        model = Trainsport_resnet50.build()\n",
        "\n",
        "        model.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "\t          metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# model.fit(dataset_train, \n",
        "#           epochs=20, \n",
        "#           steps_per_epoch=100, \n",
        "#           validation_data=dataset_test, \n",
        "#           validation_steps=20, \n",
        "#           validation_freq=5\n",
        "#          )\n",
        "\n",
        "    model.fit(x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "          epochs=20, \n",
        "          steps_per_epoch=105,\n",
        "          validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "          validation_freq=5\n",
        "         )\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NnaVTPZMPM6",
        "colab_type": "text"
      },
      "source": [
        "# 评估"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLtMHRVcVB5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce8d9bb9-0680-421a-ca40-88270180d6b5"
      },
      "source": [
        "# 保存模型到本地\n",
        "print(\"[INFO] 正在保存模型\")\n",
        "model.save('cats_dogs_classify_model.h5')\n",
        "\n",
        "# f = open('label.bin', \"wb\")\n",
        "# f.write(pickle.dumps(labl.bin))\n",
        "# f.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] 正在保存模型\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUwD3pL0LqhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0efcd1a2-3bc2-4dff-aaa7-b0bb862aa5b1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 画图\n",
        "def plot_training(history):\n",
        "        acc = history.history['acc']\n",
        "        val_acc = history.history['val_acc']\n",
        "        loss = history.history['loss']\n",
        "        val_loss = history.history['val_loss']\n",
        "        epochs = range(len(acc))\n",
        "        plt.plot(epochs, acc, 'b-')\n",
        "        plt.plot(epochs, val_acc, 'r')\n",
        "        plt.title('Training and validation accuracy')\n",
        "        \n",
        "        plt.figure()\n",
        "        plt.plot(epochs, loss, 'b-')\n",
        "        plt.plot(epochs, val_loss, 'r-')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.show()\n",
        "        \n",
        "\n",
        "plot_training(H)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0b198be0f579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mplot_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'H' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bYrpxB2RGVN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "58e4354e-67f1-4f5d-8afa-e5d5ec325dfa"
      },
      "source": [
        "x_test_all = []\n",
        "y_test_all = []\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init_op = tf.global_variables_initializer()\n",
        "    sess.run(init_op)\n",
        "    for i in range(4004//32):\n",
        "        image, label = sess.run((x_test, y_test))\n",
        "        x_test_all.append(image)\n",
        "        y_test_all.append(label)\n",
        "        # save_image('logs/%d.png' % i, image[0])\n",
        "\n",
        "x_test_all = np.array(x_test_all).reshape((-1, image_size, image_size, 3))\n",
        "\n",
        "\n",
        "y_test_all = np.array(y_test_all).reshape((-1, 2))\n",
        "\n",
        "print(x_test_all.shape)\n",
        "print(y_test_all.shape)\n",
        "\n",
        "print(x_test_all[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 224, 224, 3)\n",
            "(4000, 2)\n",
            "[[[  52.060997    -0.7789993  -65.68     ]\n",
            "  [  47.060997    -6.7789993  -76.68     ]\n",
            "  [  50.060997    -2.7789993  -84.68     ]\n",
            "  ...\n",
            "  [  90.061        7.2210007 -100.68     ]\n",
            "  [  92.061       15.221001  -103.68     ]\n",
            "  [  68.061       11.221001   -96.68     ]]\n",
            "\n",
            " [[  68.061       17.221      -53.68     ]\n",
            "  [  48.060997    -3.7789993  -78.68     ]\n",
            "  [  50.060997    -1.7789993  -86.68     ]\n",
            "  ...\n",
            "  [  95.061        9.221001   -88.68     ]\n",
            "  [  89.061       10.221001   -98.68     ]\n",
            "  [  66.061        4.2210007  -94.68     ]]\n",
            "\n",
            " [[  71.061       21.221      -53.68     ]\n",
            "  [  46.060997    -4.7789993  -83.68     ]\n",
            "  [  50.060997    -1.7789993  -87.68     ]\n",
            "  ...\n",
            "  [  93.061        7.2210007  -85.68     ]\n",
            "  [  89.061        8.221001   -93.68     ]\n",
            "  [  67.061        4.2210007  -90.68     ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ -36.939003   -70.779     -109.68     ]\n",
            "  [ -37.939003   -70.779     -112.68     ]\n",
            "  [ -25.939003   -60.779     -103.68     ]\n",
            "  ...\n",
            "  [   8.060997   -42.779     -107.68     ]\n",
            "  [  24.060997   -30.779     -102.68     ]\n",
            "  [  32.060997   -25.779     -105.68     ]]\n",
            "\n",
            " [[ -37.939003   -69.779     -109.68     ]\n",
            "  [ -39.939003   -71.779     -111.68     ]\n",
            "  [ -28.939003   -61.779     -103.68     ]\n",
            "  ...\n",
            "  [ -14.939003   -60.779     -116.68     ]\n",
            "  [   3.060997   -47.779     -112.68     ]\n",
            "  [  22.060997   -33.779     -103.68     ]]\n",
            "\n",
            " [[ -41.939003   -71.779     -111.68     ]\n",
            "  [ -41.939003   -73.779     -113.68     ]\n",
            "  [ -31.939003   -65.779     -104.68     ]\n",
            "  ...\n",
            "  [ -44.939003   -82.779     -121.68     ]\n",
            "  [ -40.939003   -82.779     -123.68     ]\n",
            "  [ -20.939003   -64.779     -116.68     ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTBlYAxMVM1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "ed514f66-8dc1-48d1-ecbd-67017d2cfa3f"
      },
      "source": [
        "\n",
        "\n",
        "# 测试网络模型\n",
        "def evaluation(model_, x_test, y_test):\n",
        "    \n",
        "#     x_test = preprocess_input(x_test)\n",
        "    \n",
        "    \n",
        "    print(\"[INFO] 正在评估模型\")\n",
        "\n",
        "    predictions = model_.predict(x_test, batch_size=200)\n",
        "\n",
        "    print(predictions.argmax(axis=1))\n",
        "\n",
        "    evaluation_score = classification_report(y_test.argmax(axis=1),\n",
        "                                             predictions.argmax(axis=1), target_names=['cats', 'dogs'])\n",
        "\n",
        "    print(evaluation_score)\n",
        "\n",
        "# evaluation(model, x_test, y_test)\n",
        "\n",
        "print('----->>>>>>')\n",
        "\n",
        "# 最好模型预测\n",
        "model_best = Trainsport_resnet50.build()\n",
        "model_best.load_weights('cats_dogs_best_model.h5')\n",
        "evaluation(model_best, x_test_all, y_test_all)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----->>>>>>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] 正在评估模型\n",
            "[0 0 0 ... 1 1 1]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cats       0.99      0.99      0.99      2002\n",
            "        dogs       0.99      0.99      0.99      1998\n",
            "\n",
            "    accuracy                           0.99      4000\n",
            "   macro avg       0.99      0.99      0.99      4000\n",
            "weighted avg       0.99      0.99      0.99      4000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}